# -*- coding: utf-8 -*-
"""DL_A2_Part_III_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SA6AvuvpNhnUP2SHoQLiHD5jFKc7tjvC
"""

import numpy as np
from PIL import Image, ImageOps
import keras
from keras.datasets import mnist
from skimage.transform import resize

# # Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Split the training set into a smaller training set and a validation set
val_size = int(len(x_train) * 0.2)
x_val, y_val = x_train[:val_size], y_train[:val_size]
x_train, y_train = x_train[val_size:], y_train[val_size:]

## Subsetting 20 percent of the data
subset_index = np.random.choice(len(x_train), size=int(len(x_train)*0.2), replace=False)
x_train_subset = x_train[subset_index]
y_train_subset = y_train[subset_index]

import cv2
def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):
    # initialize the dimensions of the image to be resized and
    # grab the image size
    dim = None
    (h, w) = image.shape[:2]

    # if both the width and height are None, then return the
    # original image
    if width is None and height is None:
        return image

    # check to see if the width is None
    if width is None:
        # calculate the ratio of the height and construct the
        # dimensions
        r = height / float(h)
        dim = (int(w * r), height)

    # otherwise, the height is None
    else:
        # calculate the ratio of the width and construct the
        # dimensions
        r = width / float(w)
        dim = (width, int(h * r))

    # resize the image
    resized = cv2.resize(image, dim, interpolation = inter)

    # return the resized image
    return resized

def resize_image(images, labels):
    augmented_images = []
    augmented_labels = []
    for image, label in zip(images, labels):
        augmented_images.append(image_resize(image))
        augmented_labels.append(label)
    return np.array(augmented_images), np.array(augmented_labels)


def left_right_flip(images, labels):
    augmented_images = []
    augmented_labels = []
    for image, label in zip(images, labels):
        flipped_image = np.fliplr(image)
        augmented_images.append(flipped_image)
        augmented_labels.append(label)
    return np.array(augmented_images), np.array(augmented_labels)

def rotate(images, labels):
    cnt = 0
    augmented_images = []
    augmented_labels = []
    try:
        for image, label in zip(images, labels):
            # Rotate the image by any random degree between -30 and 30.
            angle = np.random.randint(-30, 30)
            rotated_image = Image.fromarray(image).rotate(angle)
            rotated_image = np.array(rotated_image)
            augmented_images.append(rotated_image)
            augmented_labels.append(label)
            cnt += 1
    except:
        print(cnt)
    return np.array(augmented_images), np.array(augmented_labels)

def add_gaussian_noise(images, labels):
    augmented_images = []
    augmented_labels = []
    for image, label in zip(images, labels):
        # Add random Gaussian noise to the image
        noise = np.random.normal(loc=0.0, scale=1.0, size=image.shape)
        noisy_image = np.clip((image + noise * 50), 0, 255).astype(np.uint8)
        augmented_images.append(noisy_image)
        augmented_labels.append(label)
    return np.array(augmented_images), np.array(augmented_labels)

def best_model():
    model = Sequential()
    model.add(Conv2D(10, kernel_size=(5, 5), activation='sigmoid', input_shape=(28, 28, 1)))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(20, kernel_size=(2, 2), activation='sigmoid'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(50, activation='linear'))
    model.add(Dense(10, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
    return model

size = x_train_subset.shape[0]

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

from keras.datasets import mnist


from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout
from keras.utils import to_categorical, plot_model

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, add

"""### 1. Positional Augmentation: [2*5 = 10]
#### a. Resize your data. [2 marks]
"""

model = best_model()
tf.config.run_functions_eagerly(True)

x_train_resize, y_train_resize = resize_image(x_train_subset, y_train_subset)

x_train_updated_1 = np.concatenate([x_train, x_train_resize.reshape((size, 28, 28))])
y_train_updated_1 = np.concatenate([y_train, y_train_resize])

history_1 = model.fit(x_train_updated_1, to_categorical(y_train_updated_1),
                 batch_size=128, epochs=10, validation_data = (x_val, to_categorical(y_val)))

"""#### b. Left-right flip the original data. [2 marks]"""

x_train_flip, y_train_flip = left_right_flip(x_train_subset, y_train_subset)

x_train_updated_2 = np.concatenate([x_train, x_train_flip.reshape((size, 28, 28))])
y_train_updated_2 = np.concatenate([y_train, y_train_flip])

history_2 = model.fit(x_train_updated_2, to_categorical(y_train_updated_2),
                 batch_size=128, epochs=10, validation_data = (x_val, to_categorical(y_val)))

"""#### c. Rotate the original data by some degree. [2 marks]"""

x_train_rotate, y_train_rotate = rotate(x_train_subset.reshape((size, 28, 28)), y_train_subset)

x_train_updated_3 = np.concatenate([x_train, x_train_rotate])
y_train_updated_3 = np.concatenate([y_train, y_train_rotate])

history_3 = model.fit(x_train_updated_3, to_categorical(y_train_updated_3),
                 batch_size=128, epochs=10, validation_data = (x_val, to_categorical(y_val)))

"""#### d. Add some Gaussian noise to the original data. [2 marks]"""

x_train_gauss, y_train_gauss = add_gaussian_noise(x_train_subset, y_train_subset)

x_train_updated_4 = np.concatenate([x_train, x_train_gauss.reshape((size, 28, 28))])
y_train_updated_4 = np.concatenate([y_train, y_train_gauss])

history_4 = model.fit(x_train_updated_4, to_categorical(y_train_updated_4),
                 batch_size=128, epochs=10, validation_data = (x_val, to_categorical(y_val)))

"""#### e. Combine all the augmentation steps among the above four parts. [2 marks]"""

x_train_updated_5 = np.concatenate([x_train, 
                        x_train_resize.reshape((size, 28, 28)),
                        x_train_flip.reshape((size, 28, 28)),
                        x_train_rotate,
                        x_train_gauss.reshape((size, 28, 28)),
                                    ])

y_train_updated_5 = np.concatenate([y_train, 
                                    y_train_resize,
                                    y_train_flip,
                                    y_train_rotate,
                                    y_train_gauss])

history_5 = model.fit(x_train_updated_5, to_categorical(y_train_updated_5),
                 batch_size=128, epochs=10, validation_data = (x_val, to_categorical(y_val)))



"""## 2. Generate the following plots for each augmentation: [5 marks]
○ Loss plot - Training Loss and Validation Loss V/s Epochs.

○ Accuracy plot - Training Accuracy, Validation Accuracy V/s Epochs

(a) Plot for Resize Augumentation
"""

plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
plt.plot(history_1.history['loss'], label='Training Loss')
plt.plot(history_1.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss for Resize Augumentation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_1.history['accuracy'], label='Training Accuracy')
plt.plot(history_1.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy Resize Augumentation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

"""(b) Plot for Flip Augumentation"""

plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
plt.plot(history_2.history['loss'], label='Training Loss')
plt.plot(history_2.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss for Flip Augumentation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_2.history['accuracy'], label='Training Accuracy')
plt.plot(history_2.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy Flip Augumentation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

"""(c) PLot for Rotatation Augumentation"""

plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
plt.plot(history_3.history['loss'], label='Training Loss')
plt.plot(history_3.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss for Resize Augumentation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_3.history['accuracy'], label='Training Accuracy')
plt.plot(history_3.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy Resize Augumentation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

"""(d) Plot for Gaussian Noise Augumentation"""

plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
plt.plot(history_4.history['loss'], label='Training Loss')
plt.plot(history_4.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss for Gaussian Noise Augumentation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_4.history['accuracy'], label='Training Accuracy')
plt.plot(history_4.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy Gaussian Noise Augumentation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()



"""(e) Plot for All Augumentattions at once"""

plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
plt.plot(history_5.history['loss'], label='Training Loss')
plt.plot(history_5.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss for All Augumentations')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_5.history['accuracy'], label='Training Accuracy')
plt.plot(history_5.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy All Augumentations')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

